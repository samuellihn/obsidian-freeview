# Introduction

Physical signals such as sound, temperature, and light have historically been processed as continuous data with application-specific mechanisms and circuitry. However, as computational processing power has increased in recent years, these signals are often processed as discrete data in the form of a time series of data points. This approach has various advantages including simplified circuitry and resistance to noise and environmental interference. 

The growing prominence of matrix and vector processing in computers has necessitated the use of linear algebra for faster computation. This paper aims to outline the fundamental techniques of linear-algebra-based digital signal processing and investigate the linear filter, one application of such techniques.

## Discrete Time Signals

A discrete time signal is a sequence of numbers in the vector space $S$; that is, a function that is defined only on the integers and outputs a scalar value. This signal is generated when a continuous signal is sampled at regular intervals. Below is a discrete time signal generated by sampling the function $\sin t$ every $1/2$ seconds.

![[Pasted image 20230116114633.png]]

The points generated by this signal can be represented as an infinite sequence of numbers:

$$\set{y_k} = \set{0.0, \  0.48, \  0.84, \  1.0, \  0.91, \  0.6, \ y_7, \ y_8, \ ... \ y_n \ ...}$$

However, this only provides half the picture, as given a point in time, discrete signal processing requires knowledge of past signals as well.

## Doubly Infinite Sequences

A doubly infinite sequence is a sequence that extends infinitely in both directions. A doubly infinite sequence can also be abbreviated as $y_k$, but this time the index $k$ takes on all integers.

![[Pasted image 20230116120441.png]]

This is the same signal as the singly-infinite sequence shown above, but includes all past samples as well:

$$\set{y_k} = \set{...\ 
y_{-4}, \ 
-1.0, \  -0.84, \  -0.48, \  0.0, \  0.48, \  0.84, \  1.0, \ 
y_{4}, \ ...

}$$

Doubly infinite sequences are the fundamental unit of digital signal processing as they represent the physical signals that are being manipulated.

# Linear Difference Equations

Given a signal represented as a doubly-infinite sequence $\set{y_k}$ and scalars $a_0,\ ...,\ a_n$ with  $a_0$ and $a_n$ nonzero, a linear difference equation generates a value based on a weighted sum of previous values. When $n$ weights are given, the resultant value is based off of up to $n$ previous values in the sequence; the difference equation is therefore called an $nth$ order linear difference equation.

A general form for a linear difference equation with weights $a_0, \ ..., \ a_n$ operating on a sequence $\set{y_k}$ and outputting sequence $\set{z_k}$ is:

$$
\begin{equation}
a_0y_{k+n} + 
a_2y_{k+n-1} + 
a_3y_{k+n-2} + \ 
... \ + 
a_{n-1}y_{k+1} + 
a_ny_k = \set{z_k}
\end{equation}
$$

$a_0$ is usually set equal to $1$ for simplicity.

If the output sequence $z_k$ is the zero sequence $\set{..., \ 0, 0, 0, 0, \ ...}$, the linear difference equation is homogenous; if not, it is regarded as nonhomogeneous.

## Linear Difference Equations as Matrix Equations

A linear difference equation can also be represented as a matrix equation of the form $\vec{x_{k+1}} = A\vec{x_k}$.
$$ 
\vec{x} = 
\begin{bmatrix}
y_k\\
y_{k+1}\\
y_{k+2}\\
\vdots\\
y_{k+n-1}\\
\end{bmatrix}\ \ \ \ \ 
 A = 
\begin{bmatrix}
0 & 1 & 0 & \dotsm & 0\\
0 & 0 & 1 & & 0\\
\vdots & & & \ddots & \vdots\\
0 & 0 & 0 & & 1\\
a_n & a_{n-1} & a_{n-2} & \dotsm & a_1
\end{bmatrix}
$$
# Linear Filters

A linear formation is a linear transformation $T: S \rightarrow S$ that takes an input signal in vector space $S$, modifies it in some way, and outputs another signal in $S$. A linear filter is time-invariant, and will produce the same output given the same input no matter when the input appears. Similarly, the linear filters investigated here are causal, meaning no more than $n$ previous samples will determine the output, considering an $nth$ order linear filter.

In this paper, we will investigate homogenous linear filters that generated the zero sequence when certain frequencies are fed as inputs. Elimination of select frequencies has applications to many problems including audio processing; for example, a low-pass filter can be applied to a microphone input to remove high frequencies out of the reasonable range of human speech.

A linear filter can be represented as a linear difference equation. Although a modern approach is to implement linear filters as matrix equations, we will start out with the  arithmetic form for simplicity.

Consider the second-order linear filter represented by:

$$\begin{equation}
\tfrac{\sqrt{2}}{4}y_{k+2} + \tfrac{1}{2}y_{k+1} + \tfrac{\sqrt{2}}{4}y_{k} = z_k
\end{equation}$$

Here, the coefficients $\set{\frac{\sqrt{2}}{4}, \frac{1}{2}, \frac{\sqrt{2}}{4}}$ are called the filter coefficients of the matrix. These determine the behavior of the filter and the effects it has on incoming signals. Although observing the exact behavior of the filter at every frequency (generating the so-called "frequency response" curve) requires techniques far beyond the scope of this paper, it can be helpful to observe what happens to signals of various frequencies.

Inputting the function $\cos{\frac{t\pi}{4}}$ sampled every $1$ second into the linear filter above, the resultant waveform is:

![[Pasted image 20230116214316.png]]

Although the waveform is scaled slightly and phase shifted (as it considers past samples in each output entry), it still maintains the same frequency as the output waveform.

However, if a higher frequency signal such as $\cos{\frac{t3\pi}{4}}$ is fed into the filter, the zero sequence is outputted:

![[Pasted image 20230116214729.png]]

This filter is classified as a low-pass filter, as it allows low frequencies to pass through while attenuating (reducing the amplitude of) or eliminating higher frequencies.

## Predicting Linear Filter Behavior

## Eliminated Frequencies

As mentioned previously, predicting the frequency response curve of a linear filter requires techniques beyond the scope of this paper. However, it is straightforward to predict the frequencies which are eliminated completely or passed through unaltered using linear algebra techniques.

Consider the second-order linear filter from the previous section with filter coefficients $\set{\frac{\sqrt{2}}{4}, \frac{1}{2}, \frac{\sqrt{2}}{4}}$. 

To determine which frequencies are eliminated, consider the case where $T(\set{y_k}) \rightarrow \set{0}$Set the resultant sequence to the zero sequence, forming a homogenous linear difference equation:

$$\begin{equation}
\tfrac{\sqrt{2}}{4}y_{k+2} + \tfrac{1}{2}y_{k+1} + \tfrac{\sqrt{2}}{4}y_{k} = \set{0} 
\end{equation}$$

The sequence $r^k$ for some $r$ is often a solution of homogenous linear difference equations. To find specific solutions, it is necessary to substitute $r^k$ into the linear difference equation, creating an auxiliary equation, also called an auxiliary polynomial. If roots $r_1 \ ... r_n$ can be found for the auxiliary polynomial, then sequences $\set{{r_1}^k} \ ... \set{{r_n}^k}$ are solutions of the homogenous linear difference equation.

For a $nth$ order linear difference equation, the general form for an auxiliary polynomial is:

$$
\begin{equation}
a_0r^n + 
a_2r^n-1 + \ 
... \ + 
a_{n-1}r + 
a_n = 0
\end{equation}
$$

Therefore, the auxiliary polynomial for the linear filter shown above is:

$$\begin{equation}
\tfrac{\sqrt{2}}{4}r^2 + \tfrac{1}{2}r + \tfrac{\sqrt{2}}{4} = 0
\end{equation}$$

This is a quadratic equation, which we can see has two complex roots:

$$
\frac{
-\frac{1}{2} \pm \sqrt{\frac{1}{2}^2-4(\frac{\sqrt{2}}{2})(\frac{\sqrt{2}}{2})}
}{
2(\frac{\sqrt{2}}{{2}})
}
\rightarrow -\tfrac{\sqrt{2}}{2}\pm i\tfrac{\sqrt{2}}{2}
$$
$$r_1 = -\tfrac{\sqrt{2}}{2}+  i\tfrac{\sqrt{2}}{2}, \ r_2 = -\tfrac{\sqrt{2}}{2}- i\tfrac{\sqrt{2}}{2}$$
These complex roots can be thought of as points in the complex plane:

![[Pasted image 20230117204203.png]]
Since the two roots are complex numbers, we can write them as polar coordinates. If $R$ is the magnitude of the complex number and $\theta$ is the direction, then the complex root $r$ can be written as $R\left[\cos{\theta} + i\sin{\theta}\right]$. Applying this to the two complex roots(note that $R = 1$):

$$
r_1 = \cos{\tfrac{3\pi}{4}} + i\sin{\tfrac{3\pi}{4}}, \ 
r_2 = \cos{\tfrac{5\pi}{4}} + i\sin{\tfrac{5\pi}{4}}
$$

A theorem called De Moivre's rule of complex numbers states that for a complex number written as $r= R\left[\cos{\theta} + i\sin{\theta}\right]$, subsequent powers of that complex number can be written as $r^k = R\left[\cos{k\theta} + i\sin{k\theta}\right]$. This allows for the roots $r_1$ and $r_2$ to be generalized into sequences $\set{{r_1}^k}$ and $\set{{r_2}^k}$.

$$
{r_1}^k = \cos{\tfrac{k3\pi}{4}} + i\sin{\tfrac{k3\pi}{4}}, \ 
{r_2}^k = \cos{\tfrac{k5\pi}{4}} + i\sin{\tfrac{k5\pi}{4}}
$$

It is stated that if an auxiliary equation to a linear difference equation has a complex root $r$, then the sequences $\operatorname{Re} \set{r^k}$ and $\operatorname{Im} \set{r^k}$ are solutions to the linear difference equation. Since $\set{r^k}$ has been found above, the solutions of the linear filter are:

$$
\set{\cos{\tfrac{k3\pi}{4}}}, \ \set{\sin{\tfrac{k3\pi}{4}}}, \ 
\set{\cos{\tfrac{k5\pi}{4}}}, \ \set{\sin{\tfrac{k5\pi}{4}}}
$$

Recall that $\set{\cos{\tfrac{k3\pi}{4}}}$ was one of the frequencies completely eliminated by the linear filter. Applying the filter to $\set{\cos{\tfrac{k5\pi}{4}}}$, that frequency is filtered out completely as well:

![[Pasted image 20230117213200.png]]

To further verify our results, we can input the waveform $\cos{\frac{t}{4}} - \frac{1}{3}\cos{\frac{3t}{4}} + \frac{1}{5}\cos{\frac{5t}{4}}$ into the linear filter:

![[Pasted image 20230117222155.png]]

![[Pasted image 20230117213032.png]]

After passing the input waveform through our filter, the harmonic frequencies $\set{\cos{\tfrac{k3\pi}{4}}}$ and $\set{\cos{\tfrac{k5\pi}{4}}}$ have been completely eliminated, leaving only the unaltered wave of $\set{\cos{\tfrac{k\pi}{4}}}$.

Applying linear filters to compositions of waves shows the practical applications of linear filters. The above waveform can be thought of as a noisy waveform on which additional undesired frequencies have been added to the signal. After applying the linear filter, which functions as a low-pass filter (which eliminates higher frequencies), these undesired frequencies have been removed, thus generating a "cleaner" signal. As mentioned previously, this has applications in audio processing, where higher frequencies generated by environmental interference can be filtered out for clearer sound.

# Linear Filters as First-Order Matrix Equations

As mentioned above, a linear difference equation can be rewritten in the matrix form $\vec{x_{k+1}} = A\vec{x_k}$. Modern views of digital signal processing may prefer to view linear filters in this form, as matrix operations can have performance advantages on modern computer hardware, especially for higher-order filters with many terms. 

Using the general form described previously, our second-order linear filter can be written as a $3 \times 3$ matrix:

$$ 
\vec{x_k} = 
\begin{bmatrix}
y_k\\
y_{k+1}\\
y_{k+2}\\
\end{bmatrix}\ \ \ \ \ 
 A = 
\begin{bmatrix}
0 & 1 & 0\\
0 & 0 & 1\\
\tfrac{\sqrt{2}}{4} & \tfrac{1}{2} & \tfrac{\sqrt{2}}{4}
\end{bmatrix}
$$

# Conclusion

The rapid evolution of computer hardware has enabled numerous applications of linear algebra in various fields. This necessitates that engineers view problems in a fundamentally different perspective, as seen in this paper with the discretization of signals and signal processing techniques. By investigating one device used in digital signal processing, the linear lowpass filter, we have shown that the linear difference equation, as fundamental as it seems, can be applied to perform complex manipulations on periodic signals such as those found in sound waves. Furthermore, we have seen that solutions to homogenous systems can exhibit special behaviors in a real-world context, as seen with frequencies that are completely eliminated by linear filters. This has shown that a complete understanding of seemingly simple topics can allow for in-depth investigation of complicated real-world problems.